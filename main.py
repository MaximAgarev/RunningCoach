from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi import status
import httpx
import os
import asyncio
import json

app = FastAPI()

OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
TELEGRAM_BOT_TOKEN = os.environ["TELEGRAM_BOT_TOKEN"]
ASSISTANT_ID = os.environ["ASSISTANT_ID"]

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ: chat_id -> thread_id
user_threads = {}

@app.post("/ask")
async def ask(request: Request):
    try:
        body = await request.json()
        user_text = body["text"]
        chat_id = str(body["chat_id"])

        async with httpx.AsyncClient() as client:
            # 1. –ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å thread
            if chat_id in user_threads:
                thread_id = user_threads[chat_id]
            else:
                thread_resp = await client.post(
                    "https://api.openai.com/v1/threads",
                    headers={
                        "Authorization": f"Bearer {OPENAI_API_KEY}",
                        "OpenAI-Beta": "assistants=v2",
                        "Content-Type": "application/json"
                    }
                )
                thread_id = thread_resp.json()["id"]
                user_threads[chat_id] = thread_id

            # 2. –û—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
            await client.post(
                f"https://api.openai.com/v1/threads/{thread_id}/messages",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "OpenAI-Beta": "assistants=v2",
                    "Content-Type": "application/json"
                },
                json={"role": "user", "content": user_text}
            )

            # 3. –ó–∞–ø—É—Å—Ç–∏—Ç—å run
            run_resp = await client.post(
                f"https://api.openai.com/v1/threads/{thread_id}/runs",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "OpenAI-Beta": "assistants=v2",
                    "Content-Type": "application/json"
                },
                json={"assistant_id": ASSISTANT_ID}
            )
            run = run_resp.json()
            run_id = run["id"]

            # 4. –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è run –∏–ª–∏ requires_action
            for _ in range(30):
                run_status_resp = await client.get(
                    f"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}",
                    headers={
                        "Authorization": f"Bearer {OPENAI_API_KEY}",
                        "OpenAI-Beta": "assistants=v2"
                    }
                )
                run_status = run_status_resp.json()
                status_ = run_status["status"]

                if status_ in ["completed", "failed"]:
                    break

                elif status_ == "requires_action":
                    tool_calls = run_status["required_action"]["submit_tool_outputs"]["tool_calls"]

                    tool_outputs = []
                    for call in tool_calls:
                        function_name = call["function"]["name"]
                        arguments = json.loads(call["function"]["arguments"])

                        # üëâ –ó–¥–µ—Å—å –≤—ã–∑—ã–≤–∞–µ–º –Ω–∞—Å—Ç–æ—è—â–∏–π —ç–Ω–¥–ø–æ–∏–Ω—Ç Notion Proxy
                        notion_response = await client.post(
                            f"http://notion-proxy:8000/{function_name}",  # Docker internal URL
                            json=arguments
                        )
                        notion_result = notion_response.json()

                        tool_outputs.append({
                            "tool_call_id": call["id"],
                            "output": json.dumps(notion_result)
                        })

                    await client.post(
                        f"https://api.openai.com/v1/threads/{thread_id}/runs/{run_id}/submit_tool_outputs",
                        headers={
                            "Authorization": f"Bearer {OPENAI_API_KEY}",
                            "OpenAI-Beta": "assistants=v2",
                            "Content-Type": "application/json"
                        },
                        json={"tool_outputs": tool_outputs}
                    )

                await asyncio.sleep(0.3)

            # 5. –ü–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            messages_resp = await client.get(
                f"https://api.openai.com/v1/threads/{thread_id}/messages",
                headers={
                    "Authorization": f"Bearer {OPENAI_API_KEY}",
                    "OpenAI-Beta": "assistants=v2"
                }
            )
            messages = messages_resp.json()["data"]

            assistant_reply = "ü§ñ –û—à–∏–±–∫–∞: –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç."
            for msg in messages:
                if msg["role"] == "assistant" and "content" in msg:
                    for part in msg["content"]:
                        if part["type"] == "text":
                            assistant_reply = part["text"]["value"]
                            break
                    break

            # 6. –û—Ç–≤–µ—Ç –≤ Telegram
            await client.post(
                f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage",
                json={"chat_id": chat_id, "text": assistant_reply}
            )

        return {"status": "ok"}

    except Exception as e:
        print("‚ùå ERROR:", str(e))
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={"error": str(e)}
        )

@app.api_route("/ping", methods=["GET", "HEAD"])
async def ping():
    return {"status": "alive"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=3000)
